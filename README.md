
---

````md
# ğŸ§  Friendly Mental Health Chatbot

A Retrieval-Augmented Generation (RAG)-based chatbot that provides empathetic and helpful responses grounded in reliable mental health resources. Ideal for offering emotional support, this assistant uses vector-based retrieval and local LLM generation for informed, emotionally intelligent responses.

---

ğŸ§© Problem Statement

Many individuals seek emotional support but hesitate to approach professionals or find it difficult to search through mental health literature. This chatbot addresses that by enabling **accessible, reliable, and emotionally aware guidance**, grounded in real mental health resources.

Unlike generic LLM-based bots, this system uses **Retrieval-Augmented Generation (RAG)** to provide **fact-based responses**, reducing hallucinations and increasing relevance.

---

ğŸ§  Why RAG?

RAG improves trustworthiness by retrieving relevant text passages from verified content (e.g., therapy guides or support articles) and **feeding them to the LLM** before generation. This ensures responses are **informed and grounded**, not hallucinated.

---

ğŸ—ï¸ RAG Architecture Overview

ğŸ”¹ Data Used for Retrieval
- A curated file: `mental_health_resources.txt`  
  Contains supportive advice, therapy techniques, and emotional wellness tips.

ğŸ”¹ Retrieval Component
- **Vector Store**: ChromaDB  
- **Embedding Model**: `all-MiniLM-L6-v2` via Hugging Face  
- **Document Splitter**: LangChain `RecursiveCharacterTextSplitter`  

ğŸ”¹ Generation Component
- **LLM**: `llama3` via Ollama  
- **Framework**: LangChain  
- **Prompting Strategy**: Custom RAG prompt with retrieved context

---

 ğŸ› ï¸ Tools and Frameworks

- **LangChain** â€“ RAG pipeline management  
- **ChromaDB** â€“ Vector store for retrieval  
- **Ollama** â€“ Runs LLaMA 3 locally for fast, offline generation  
- **Hugging Face Transformers** â€“ Embeddings with `sentence-transformers`  
- **Matplotlib** â€“ Optional analysis of response time  

---

 ğŸ§ª LLM Details

- **LLM Used**: `llama3` via [Ollama](https://ollama.com) (local inference)
- **Embedding Model**: `all-MiniLM-L6-v2` from Sentence-Transformers
- **Free-Tier Friendly**: All tools run locally; no paid APIs required

---

 ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/your-repo/chatbot.git
cd chatbot
````

### 2. (Optional) Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Start Ollama

Ensure you have [Ollama](https://ollama.com) installed and the `llama3` model downloaded:

```bash
ollama run llama3
```

### 5. Add Your Resource File

Place the `mental_health_resources.txt` file in the project directory.

---

## ğŸ’¬ Run the Chatbot

```bash
python chatbot.py
```

* Type your message to receive a short, friendly response.
* Type `exit` or `quit` to end the chat and view performance plot.

---

## ğŸ“Š Visualize Response Time

After exiting, a Matplotlib plot will show LLM response time per user interaction.

---

## ğŸ“ Project Structure

```
chatbot/
â”‚
â”œâ”€â”€ chatbot.py                  # Main chatbot script
â”œâ”€â”€ mental_health_resources.txt # Your knowledge base
â”œâ”€â”€ requirements.txt            # Dependency list
â””â”€â”€ README.md                   # This file
```

---

## ğŸ“¦ Dependencies (`requirements.txt`)

```txt
langchain
langchain-community
langchain-core
langchain-ollama
langchain-huggingface
huggingface_hub
sentence-transformers
chromadb
matplotlib
asyncio
```


## ğŸ™ Acknowledgements

* [LangChain](https://www.langchain.com/)
* [Ollama](https://ollama.com/)
* [Hugging Face](https://huggingface.co/)
* [ChromaDB](https://www.trychroma.com/)

---

## ğŸ’™ Disclaimer

This chatbot is a demo and **not a substitute for professional mental health support**.
Please consult a licensed mental health professional when needed.

```



